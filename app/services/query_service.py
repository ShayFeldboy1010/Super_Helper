import logging
import json
from app.core.database import supabase
from app.services.google_svc import GoogleService
from groq import AsyncGroq
from app.core.config import settings
import os

logger = logging.getLogger(__name__)
client = AsyncGroq(api_key=settings.GROQ_API_KEY)

class QueryService:
    def __init__(self, user_id: int):
        self.user_id = user_id
        self.google = GoogleService(user_id)

    async def answer_query(self, query_text: str, context_needed: list[str], target_date: str = None, memory_context: str = "") -> str:
        context_data = []

        # 1. Fetch Calendar if needed or default
        if "calendar" in context_needed or not context_needed:
            events = await self.google.get_events_for_date(target_date)
            date_label = target_date if target_date else "×”×™×•×"
            context_data.append(f"ğŸ“… ××™×¨×•×¢×™× ×‘-{date_label}:\n" + "\n".join(events))

        # 2. Fetch Tasks if needed or default
        if "tasks" in context_needed or not context_needed:
            try:
                response = supabase.table("tasks").select("*").eq("user_id", self.user_id).eq("status", "pending").execute()
                tasks = response.data
                if tasks:
                    task_list = "\n".join([f"- {t['title']} (Due: {t.get('due_at')})" for t in tasks])
                    context_data.append(f"âœ… ××©×™××•×ª ×¤×ª×•×—×•×ª:\n{task_list}")
                else:
                    context_data.append("âœ… ××™×Ÿ ××©×™××•×ª ×¤×ª×•×—×•×ª.")
            except Exception as e:
                logger.error(f"Error fetching tasks: {e}")

        # 3. Fetch Notes
        if "notes" in context_needed:
             try:
                response = supabase.table("archive").select("content, tags").eq("user_id", self.user_id).order("created_at", desc=True).limit(5).execute()
                notes = response.data
                if notes:
                    note_list = "\n".join([f"- {n['content']} (Tags: {n['tags']})" for n in notes])
                    context_data.append(f"ğŸ“ ×”×¢×¨×•×ª ××—×¨×•× ×•×ª:\n{note_list}")
             except Exception as e:
                logger.error(f"Error fetching notes: {e}")

        # 4. Fetch Emails
        if "email" in context_needed:
            try:
                emails = await self.google.get_recent_emails(max_results=5)
                if emails:
                    email_lines = []
                    for e in emails:
                        email_lines.append(f"- ×××ª: {e['from']} | × ×•×©×: {e['subject']}\n  {e['snippet'][:100]}")
                    context_data.append(f"ğŸ“§ ××™××™×™×œ×™× ××—×¨×•× ×™×:\n" + "\n".join(email_lines))
                else:
                    context_data.append("ğŸ“§ ××™×Ÿ ××™××™×™×œ×™× ××—×¨×•× ×™×.")
            except Exception as e:
                logger.error(f"Error fetching emails: {e}")

        # 5. Generate Answer with LLM
        full_context = "\n\n".join(context_data)

        system_prompt = (
            "××ª×” ×¨××© ××˜×” ××™×©×™ (Chief of Staff). ×¤×•×¨××˜ BLUF â€” ×©×•×¨×” ×ª×—×ª×•× ×” ×§×•×“×.\n"
            "×¢× ×” ×ª××™×“ ×‘×¢×‘×¨×™×ª. ×ª××¦×™×ª×™, ×™×©×™×¨, ×œ×œ× ××™×œ×•×ª ××™×œ×•×™.\n"
            "â€¢ ×‘×•×œ×˜×™×, ×œ× ×¤×¡×§××•×ª\n"
            "â€¢ ×”××™×“×¢ ×”×—×©×•×‘ ×‘×™×•×ª×¨ â€” ×§×•×“×\n"
            "â€¢ ×× ××™×Ÿ ×ª×©×•×‘×” ×‘××™×“×¢ â€” ×××•×¨ ×©××™× ×š ×™×•×“×¢\n"
            "â€¢ ××œ ×ª×•×¡×™×£ ×¡×™×¡×××•×ª ××•×˜×™×‘×¦×™×”. ×ª×Ÿ ××™×“×¢, ×œ× × ××•××™×.\n"
            "â€¢ ×× ×™×© ×¤×¢×•×œ×” ××•××œ×¦×ª â€” ×”×¦×¢ ××•×ª×” ×‘×¡×•×£"
        )

        if memory_context:
            system_prompt += (
                "\n\n××™×“×¢ ×©× ×¦×‘×¨ ×¢×œ ×”××©×ª××© (×”×©×ª××© ×‘×• ×‘×˜×‘×¢×™×•×ª, ×‘×œ×™ ×œ×”×–×›×™×¨ ×©×™×© ×œ×š ××•×ª×•):\n"
                + memory_context
            )

        try:
            chat_completion = await client.chat.completions.create(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"Context:\n{full_context}\n\nQuestion: {query_text}"}
                ],
                model="moonshotai/kimi-k2-instruct-0905",
                temperature=0.7,
            )
            return chat_completion.choices[0].message.content
        except Exception as e:
            logger.error(f"LLM generation error: {e}")
            return "âŒ × ×ª×§×œ×ª×™ ×‘×©×’×™××” ×‘×¢×ª ×‘×“×™×§×ª ×”× ×ª×•× ×™× ×©×œ×š."
